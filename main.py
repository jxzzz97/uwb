import feedparser
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re
import time
import urllib.parse

# --- 1. æ ¸å¿ƒå…³é”®è¯é…ç½® ---
TARGET_KEYWORDS = [
    "UWB", "Ultra-Wideband", "Ultra Wideband", "è¶…å®½å¸¦", 
    "FiRa", "802.15.4z", "CCC Digital Key", 
    "NXP", "Qorvo", "STMicroelectronics", "Apple U1", 
    "çº½ç‘èŠ¯", "NewRadio", "é©°èŠ¯", "Cixin", "åŠ ç‰¹å…°", "Calterah",
    "ç²¾ä½ç§‘æŠ€", "å…¨è¿¹ç§‘æŠ€", "TSingo", "ä¿¡ç»´é€šä¿¡", "æµ©äº‘ç§‘æŠ€"
]

# --- 2. æ„é€ æœç´¢æº ---
def get_google_rss_url(query):
    encoded_query = urllib.parse.quote(query)
    return f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"

RSS_FEEDS = [
    "https://techcrunch.com/tag/ultra-wideband/feed/",
    "https://www.iotforall.com/feed",
    "https://www.macrumors.com/macrumors.xml",
    "https://www.iot-now.com/feed/",
    "https://9to5mac.com/feed/",
    "https://www.theverge.com/rss/index.xml",
    get_google_rss_url("UWB èŠ¯ç‰‡"),
    get_google_rss_url("UWB äº§ä¸š"),
    get_google_rss_url("AirTag"),
    get_google_rss_url("Apple UWB"),
    get_google_rss_url("è¶…å®½å¸¦æŠ€æœ¯"),
    get_google_rss_url("çº½ç‘èŠ¯ OR é©°èŠ¯ OR åŠ ç‰¹å…° OR æ©æ™ºæµ¦ UWB"),
]

# --- 3. è¾…åŠ©å·¥å…· ---
def clean_summary(html_text, source_name=""):
    if not html_text: return ""
    try:
        soup = BeautifulSoup(html_text, 'html.parser')
        text = soup.get_text(separator=' ')
        text = re.sub(r'\s+', ' ', text).strip()
        
        # æ¸…æ´— Google News å°¾å·´
        text = text.replace("Google æ–°é—»çš„å®Œæ•´æŠ¥é“", "").replace("See full coverage on Google News", "")
        
        # åˆ‡æ‰æ¥æºåç§°
        if source_name and len(source_name) > 1:
            text = re.sub(re.escape(source_name), '', text, flags=re.IGNORECASE).strip()
            text = text.rstrip(" -|:ï¼š")

        return text
    except:
        return html_text[:100]

def is_recent(entry_date_parsed):
    if not entry_date_parsed: return True 
    try:
        news_date = datetime.fromtimestamp(time.mktime(entry_date_parsed))
        return (datetime.now() - news_date).days <= 30
    except:
        return True 

def check_keywords(text):
    text = text.lower()
    for kw in TARGET_KEYWORDS:
        if kw.lower() in text:
            return True
    return False

# --- 4. æ™ºèƒ½åˆ†ç±»é€»è¾‘ ---
def get_category(title, summary):
    text = (title + summary).lower()
    if any(k in text for k in ["fira", "802.15.4z", "ccc", "alliance", "è”ç›Ÿ", "æ ‡å‡†", "åè®®"]):
        return "standards"
    
    chip_keywords = [
        "nxp", "qorvo", "apple", "stmicro", "çº½ç‘èŠ¯", "é©°èŠ¯", 
        "åŠ ç‰¹å…°", "èŠ¯ç‰‡", "ic", "åŠå¯¼ä½“", "å‘å¸ƒ"
    ]
    if any(k in text for k in chip_keywords):
        return "chips"
        
    return "general"

# é’ˆå¯¹ FiRa å®˜ç½‘
def scrape_fira_news():
    url = "https://www.firaconsortium.org/about/news-events/press-releases"
    return [{
        'title': "FiRa è”ç›Ÿå®˜æ–¹æ–°é—»ä¸­å¿ƒ (ç‚¹å‡»ç›´è¾¾)",
        'link': url,
        'source': 'FiRa Consortium',
        'date': datetime.now().timetuple(),
        'summary': "FiRa è”ç›Ÿå®˜æ–¹å‘å¸ƒçš„æœ€æ–°æ ‡å‡†ã€è®¤è¯äº§å“åŠæˆå‘˜åŠ¨æ€ã€‚",
        'category': 'standards'
    }]

# --- 5. æ ¸å¿ƒé€»è¾‘ ---
def fetch_feed(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'application/rss+xml, application/xml, text/xml, */*'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8' 
        if response.status_code != 200: return None
        return feedparser.parse(response.content)
    except: return None

def generate_newsletter():
    articles = []
    print("ğŸš€ å¼€å§‹å…¨ç½‘æŠ“å–...")
    
    # 1. æŠ“å–
    for url in RSS_FEEDS:
        feed = fetch_feed(url)
        if not feed or not feed.entries: continue
            
        for entry in feed.entries:
            if hasattr(entry, 'published_parsed') and not is_recent(entry.published_parsed):
                continue
            
            summary_raw = entry.get('summary', entry.get('description', ''))
            content_to_check = f"{entry.title} {summary_raw}"
            
            if check_keywords(content_to_check):
                source_name = feed.feed.get('title', 'Network Source')
                title_clean = entry.title
                real_source_name_for_cleaning = "" 

                if "Google" in source_name:
                    source_name = "Google News"
                
                if " - " in title_clean:
                    parts = title_clean.rsplit(" - ", 1)
                    title_clean = parts[0]
                    real_source = parts[1]
                    source_name = f"{real_source}"
                    real_source_name_for_cleaning = real_source 

                # æ¸…æ´—æ‘˜è¦
                final_summary = clean_summary(summary_raw, real_source_name_for_cleaning)

                # ğŸ”¥ æ™ºèƒ½éšè—é€»è¾‘ ğŸ”¥
                # å»é™¤æ ‡ç‚¹å’Œç©ºæ ¼è¿›è¡Œæ ¸å¿ƒå†…å®¹æ¯”å¯¹
                t_core = re.sub(r'[^\w]', '', title_clean)
                s_core = re.sub(r'[^\w]', '', final_summary)
                
                # å¦‚æœæ‘˜è¦è¢«åŒ…å«åœ¨æ ‡é¢˜é‡Œï¼Œæˆ–è€…æ ‡é¢˜åŒ…å«åœ¨æ‘˜è¦é‡Œï¼Œåˆ¤å®šä¸ºé‡å¤
                if len(s_core) > 0 and (s_core in t_core or t_core in s_core):
                    # å¦‚æœé•¿åº¦å·®å¼‚å¾ˆå°ï¼ˆè¯´æ˜æ²¡æœ‰é¢å¤–ä¿¡æ¯ï¼‰ï¼ŒæŠŠæ‘˜è¦è®¾ä¸ºç©º
                    if abs(len(s_core) - len(t_core)) < 20:
                        final_summary = "" # å½»åº•æ¸…ç©ºï¼Œä¸æ˜¾ç¤º
                
                # å¦‚æœæ‘˜è¦æœ¬èº«å°±å¤ªçŸ­ï¼Œä¹Ÿéšè—
                if len(final_summary) < 5:
                    final_summary = ""

                # æˆªæ–­è¿‡é•¿æ‘˜è¦
                if len(final_summary) > 120: 
                    final_summary = final_summary[:120] + "..."

                category = get_category(title_clean, summary_raw)

                articles.append({
                    'title': title_clean,
                    'link': entry.link,
                    'source': source_name,
                    'date': entry.get('published_parsed', datetime.now().timetuple()),
                    'summary': final_summary, # è¿™é‡Œå¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²
                    'category': category
                })

    # 2. åŠ å…¥ FiRa å¹¶å»é‡
    articles.extend(scrape_fira_news())
    seen_links = set()
    unique_articles = []
    for art in articles:
        if art['link'] not in seen_links:
            unique_articles.append(art)
            seen_links.add(art['link'])
    
    unique_articles.sort(key=lambda x: time.mktime(x['date']) if x['date'] else 0, reverse=True)

    # 3. åˆ†ç»„
    modules = {
        "standards": [],
        "chips": [],
        "general": []
    }
    for art in unique_articles:
        modules[art['category']].append(art)

    # 4. ç”Ÿæˆ HTML
    cat_titles = {
        "standards": "ğŸ›ï¸ æƒå¨å‘å¸ƒ & æ ‡å‡†åŠ¨æ€",
        "chips": "ğŸ’ èŠ¯ç‰‡åŸå‚ & æ ¸å¿ƒæŠ€æœ¯",
        "general": "ğŸ“° è¡Œä¸šåº”ç”¨ & å¸‚åœºèµ„è®¯"
    }

    content_html = ""
    for cat_key, arts in modules.items():
        if not arts: continue 
        
        section_html = f"""
        <div class="section-header">{cat_titles[cat_key]}</div>
        <div class="news-grid">
        """
        
        for art in arts:
            try: date_str = time.strftime('%m-%d', art['date'])
            except: date_str = "Recent"
            
            # ğŸ”¥ HTML ç”Ÿæˆæ—¶çš„åˆ¤æ–­é€»è¾‘ ğŸ”¥
            # åªæœ‰å½“ summary ä¸ä¸ºç©ºæ—¶ï¼Œæ‰ç”Ÿæˆ <p> æ ‡ç­¾
            summary_html = ""
            if art['summary']:
                summary_html = f'<p class="summary">{art["summary"]}</p>'
            
            section_html += f"""
            <div class="card">
                <div class="meta-info">
                    <span class="tag">{cat_key.upper()}</span>
                    <span class="source">{art['source']} Â· {date_str}</span>
                </div>
                <a href="{art['link']}" class="title-link" target="_blank">{art['title']}</a>
                {summary_html}
            </div>
            """
        section_html += "</div>"
        content_html += section_html

    if not unique_articles:
        content_html = '<div class="empty-msg"><h3>ğŸ“¡</h3><p>æ­£åœ¨æ‰«æå…¨ç½‘æ•°æ®...</p></div>'

    html_template = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Tiagile - UWB & IoT è¡Œä¸šæƒ…æŠ¥</title>
        <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&family=Noto+Sans+SC:wght@400;700&display=swap" rel="stylesheet">
        <style>
            :root {{ --primary-color: #0061ff; --bg-color: #f4f7fa; }}
            body {{
                font-family: 'Poppins', 'Noto Sans SC', sans-serif;
                margin: 0; padding: 0;
                background-color: var(--bg-color);
                background-image: linear-gradient(rgba(244, 247, 250, 0.9), rgba(244, 247, 250, 0.9)), url('https://images.unsplash.com/photo-1451187580459-43490279c0fa?auto=format&fit=crop&w=1920&q=80');
                background-size: cover; background-attachment: fixed;
                color: #333;
            }}
            .main-container {{
                max-width: 1000px;
                margin: 40px auto; padding: 20px;
            }}
            .header-section {{ text-align: center; margin-bottom: 40px; padding: 20px; }}
            h1 {{
                font-weight: 800; font-size: 2.5rem; margin: 0;
                background: linear-gradient(135deg, #0061ff, #60efff); -webkit-background-clip: text; -webkit-text-fill-color: transparent;
                letter-spacing: -1px;
            }}
            .date {{ color: #666; font-weight: 600; margin-top: 5px; font-size: 0.9rem; text-transform: uppercase; }}

            .section-header {{
                font-size: 1.4rem; font-weight: 700; color: #2c3e50;
                margin: 30px 0 15px 0; padding-left: 15px;
                border-left: 5px solid var(--primary-color);
            }}
            
            .news-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
                gap: 20px;
            }}

            .card {{
                background: #ffffff; padding: 20px;
                border-radius: 12px;
                box-shadow: 0 4px 10px rgba(0,0,0,0.03);
                transition: transform 0.2s, box-shadow 0.2s;
                border: 1px solid rgba(0,0,0,0.05);
                display: flex; flex-direction: column;
            }}
            .card:hover {{ transform: translateY(-4px); box-shadow: 0 10px 20px rgba(0,0,0,0.08); }}
            
            .meta-info {{ display: flex; align-items: center; margin-bottom: 10px; font-size: 0.8em; }}
            .tag {{ 
                background: #eef4ff; color: var(--primary-color); 
                padding: 3px 8px; border-radius: 6px; font-weight: 700; margin-right: 8px; 
            }}
            .source {{ color: #888; font-weight: 600; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }}
            
            a.title-link {{ 
                text-decoration: none; color: #1a1a1a; font-size: 1.1rem; font-weight: 700; 
                line-height: 1.4; margin-bottom: 5px; /* å‡å°ä¸‹è¾¹è·ï¼Œå› ä¸ºå¯èƒ½æ²¡æœ‰æ‘˜è¦ */
                display: block;
            }}
            a.title-link:hover {{ color: var(--primary-color); }}
            
            .summary {{ 
                color: #555; font-size: 0.9rem; line-height: 1.6; 
                margin: 5px 0 0 0; /* è°ƒæ•´é—´è· */
                flex-grow: 1; 
            }}

            .footer {{ margin-top: 60px; text-align: center; color: #aaa; font-size: 0.8rem; padding-bottom: 20px; }}
            .tiagile-logo {{ font-size: 1.5rem; font-weight: 800; color: #2c3e50; }}
            .tiagile-logo span {{ color: #0061ff; }}

            @media (max-width: 600px) {{
                .news-grid {{ grid-template-columns: 1fr; }}
                h1 {{ font-size: 2rem; }}
            }}
        </style>
    </head>
    <body>
        <div class="main-container">
            <div class="header-section">
                <h1>âš¡ï¸ UWB & IoT è¡Œä¸šæƒ…æŠ¥ç«™</h1>
                <p class="date">{datetime.now().strftime('%Y.%m.%d')} | Tiagile Daily Briefing</p>
            </div>
            
            {content_html}

            <div class="footer">
                <div class="tiagile-logo">T<span>i</span>agile</div>
                <p>Intelligence Powered by GitHub Actions</p>
            </div>
        </div>
    </body>
    </html>
    """
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_template)
    print("å®Œæˆï¼index.html å·²ç”Ÿæˆã€‚")

if __name__ == "__main__":
    generate_newsletter()

